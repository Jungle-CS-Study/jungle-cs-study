

## 부하 테스트 

### 1. 도입: 왜 부하 테스트를 해야 하는가?

#### "우리 서비스, 사용자가 몰려도 괜찮은가?"

블랙 프라이데이 세일, 인기 아이돌의 콘서트 티켓팅, 혹은 성공적인 마케팅 캠페인 직후와 같이 서비스 사용자가 갑자기 폭증하는 순간이 있다. 이때 서버가 응답하지 않거나 웹페이지가 열리지 않는다면, 사용자는 즉시 이탈하고 비즈니스는 막대한 손실을 입는다.

**부하 테스트**는 이런 상황을 미리 대비하고, 우리 시스템이 감당할 수 있는 한계와 성능을 과학적으로 측정하는 과정이다. 장애 발생 후 대응하는 것이 아니라, 사전에 문제를 발견하고 개선하기 위한 **선제적인 품질 관리 활동이다.**

#### 부하 테스트의 정의

> \*\*부하 테스트(Load Testing)\*\*란 특정 부하(예: 동시 사용자 1,000명)를 시스템에 가하여, 시스템의 성능 지표(응답 시간, 처리량 등)를 측정하고 분석하여 성능 목표를 만족하는지 확인하는 테스트다.

#### 성능 테스트의 종류별 차이점

| 종류 | 목적 | 부하 방식 | 주요 질문 |
| :--- | :--- | :--- | :--- |
| **부하 (Load) 테스트** | **예상되는** 부하 상황에서 성능 목표를 만족하는지 확인한다. | 점진적으로 부하를 예상치까지 증가시킨다. | "평상시 동시 접속자 500명을 잘 처리하는가?" |
| **스트레스 (Stress) 테스트** | 시스템의 **한계점**을 찾기 위해 부하를 임계치 이상으로 가한다. | 부하를 임계치 이상으로 계속 증가시킨다. | "서버는 언제 다운되는가? 복구는 가능한가?" |
| **스파이크 (Spike) 테스트** | **순간적인** 트래픽 폭증을 시스템이 감당하는지 확인한다. | 짧은 시간에 부하를 급격히 증가/감소시킨다. | "티켓팅 오픈 1분 동안 몰리는 트래픽을 감당하는가?" |

-----

### 2\. 핵심 개념: 무엇을 측정하고 분석하는가 (주요 성능 지표)

부하 테스트의 결과는 여러 지표로 표현된다. 이 숫자들의 의미를 알아야 정확한 분석이 가능하다.

  * `📈 응답 시간 (Response Time)`: 사용자가 요청을 보낸 후 **최종 응답을 받기까지** 걸린 시간이다. (단위: ms)

      * **Latency**와는 미묘하게 다르다. Latency는 서버의 순수 처리 시간이며, Response Time은 네트워크 시간을 포함한 사용자 체감 시간이다.
      * **p(95), p(99)** 같은 백분위수 지표가 중요하다. `p(95) 250ms`는 "전체 요청의 95%가 250ms 이내에 처리되었다"는 의미이며, 평균값보다 실제 사용자 경험을 더 잘 대변한다.

  * `⚙️ 처리량 (Throughput)`: 시스템이 단위 시간당 처리하는 요청의 수다.

      * **RPS (Requests Per Second)**: 초당 요청 수
      * **TPS (Transactions Per Second)**: 초당 트랜잭션 수
      * 처리량이 높을수록 더 효율적인 시스템이다.

  * `⚠️ 에러율 (Error Rate)`: 전체 요청 중 실패한 요청(5xx 에러 등)의 비율이다.

      * 에러율이 0%에 가까울수록 안정적인 시스템이다.

  * `👥 동시 사용자 (Concurrent Users / Virtual Users)`: 특정 시점에 **동시에** 시스템과 상호작용하는 가상 사용자 수이며, 부하의 크기를 결정하는 핵심 요소다.

  * `💻 자원 사용량 (Resource Utilization)`: 부하가 발생하는 동안의 서버 상태다.

      * CPU 사용률, 메모리 사용량, 디스크 I/O, 네트워크 대역폭 등을 확인하여 시스템의 병목 지점을 찾는다.

-----

### 3\. 프로세스: 부하 테스트 진행 단계 (A to Z)

**1️⃣ 단계: 목표 설정 (Goal Setting)**
가장 중요한 첫 단계로, 구체적이고 측정 가능한 목표를 설정해야 한다.

  * (Bad 👎) "회원가입 기능이 빨라져야 한다."
  * (Good 👍) "회원가입 API는 **1,000 RPS**의 부하에서 **평균 응답시간 200ms 이하, p(99) 500ms 이하**를 유지하고 **에러율은 0.1% 미만**이어야 한다."

**2️⃣ 단계: 시나리오 설계 (Scenario Design)**
실제 사용자의 행동 패턴과 최대한 유사하게 시나리오를 설계해야 유의미한 결과를 얻을 수 있다.

  * **단일 API 테스트**: 특정 기능의 성능을 집중적으로 측정한다.
  * **복합 시나리오 테스트**: 실제 사용자 흐름(로그인 → 상품 검색 → 결제 시도)을 모방한다.

**3️⃣ 단계: 테스트 환경 준비 및 스크립트 작성**
운영 환경에서의 테스트는 매우 위험하므로 별도의 테스트 환경을 구축한다.

  * **도구 선정**: JMeter, nGrinder, Gatling, **k6** 등 프로젝트 특성과 팀 기술 스택에 맞는 도구를 선택한다.
  * **스크립트 작성**: 2단계에서 설계한 시나리오를 코드로 구현한다.

**4️⃣ 단계: 테스트 실행 및 모니터링**
스크립트를 실행하여 부하를 발생시키고, APM이나 서버 모니터링 도구를 통해 시스템 자원 사용량을 실시간으로 관찰한다.

**5️⃣ 단계: 결과 분석 및 병목 지점(Bottleneck) 식별**
테스트 종료 후 결과를 분석한다.

  * 설정한 목표(1단계)를 달성했는가?
  * 부하 증가에 따라 응답 시간이 급격히 늘어나는 지점은 어디인가?
  * 특정 자원(CPU, DB Connection 등)이 한계에 도달하여 성능 저하를 유발하는가?
  * 이러한 성능 저하의 원인, 즉 \*\*병목(Bottleneck)\*\*을 찾아낸다.

**6️⃣ 단계: 튜닝 및 개선, 그리고 재테스트**
병목 지점을 개선한다. (예: SQL 튜닝, 코드 로직 최적화, 캐시 적용, 인프라 증설 등)
개선 완료 후, **동일한 조건으로 다시 테스트**하여 개선 효과를 검증한다. 이 과정은 목표를 달성할 때까지 반복된다.

-----

### 4. 실전: k6를 이용한 API 부하 테스트

**k6**는 Grafana Labs에서 만든 오픈소스 부하 테스트 도구이다.

  * **장점**: JavaScript로 스크립트를 작성하여 개발자에게 친숙하고, 코드 기반으로 버전 관리가 용이하며, 성능이 우수하다.

**실습

아래는 특정 API에 **10명의 가상 유저(VUs)가 30초 동안** 지속적으로 요청을 보내는 시나리오다.

```javascript
// 1. k6 스크립트 파일 (예: script.js)
import http from 'k6/http';
import { sleep, check } from 'k6';

// 2. 테스트 옵션 설정: 부하의 형태를 정의한다.
export const options = {
  vus: 10,          // 가상 유저 10명
  duration: '30s',  // 30초 동안 테스트 수행
};

// 3. 테스트 로직: 각 가상 유저가 반복 실행할 코드다.
export default function () {
  const res = http.get('https://test-api.k6.io/public/crocodiles/1/');

  // 4. 응답 검증 (Assertion)
  check(res, {
    'status is 200': (r) => r.status === 200,
  });

  // 다음 요청 전 1초간 대기한다.
  sleep(1);
}
```

**🚀 실행 및 결과 해석**

터미널에서 `k6 run script.js` 명령어로 실행한다. 실행 후 출력되는 결과에서 다음 항목을 주목한다.

```
     ✓ status is 200

     checks.........................: 100.00% ✓ 280        ✗ 0
     data_received..................: 126 kB  4.2 kB/s
     data_sent......................: 26 kB   870 B/s
     http_req_blocking..............: avg=6.12ms   min=1.01µs   med=2.1µs    max=176.01ms p(90)=3.65µs   p(95)=17.2ms
     http_req_connecting............: avg=2.08ms   min=0s       med=0s       max=67.9ms   p(90)=0s       p(95)=12.2ms
   ✓ http_req_duration..............: avg=112.91ms min=102.32ms med=110.1ms  max=188.77ms p(90)=123.6ms  p(95)=129.47ms
     http_req_failed................: 0.00%   ✓ 0          ✗ 280
     http_reqs......................: 280     9.35565/s
     iterations.....................: 280     9.35565/s
```

  * `http_reqs`: **총 280번**의 요청을 보냈고, 초당 **9.35개**를 처리했다. (처리량)
  * `http_req_duration`: **p(95)가 129.47ms**이다. 즉, 95%의 요청이 129.47ms 안에 처리되었다. (응답 시간)
  * `checks`: 검증이 **100% 성공**했다. (에러율 0%)

-----

### 5. 실전 스트레스 테스트 사례 분석

이론적인 내용을 넘어, 실제 테스트가 어떻게 진행되고 어떤 의미를 갖는지 구체적인 사례를 통해 분석한다.

#### 테스트 개요

* **테스트 대상:** 실제 운영했던 Spring Boot 기반의 '오몰리' 쇼핑몰 서비스
* **테스트 환경:**
    * **클라이언트:** 외부 기가 인터넷 회선
    * **서버:** 운영 환경에 배포된 서버 (AMD Ryzen 7 5800X, Ubuntu 22.04)
    * **네트워크:** 클라이언트와 서버 간 Ping 약 65ms (외부 인터넷망 경유)
* **테스트 도구:** k6
* **테스트 목적:** 시스템이 감당할 수 있는 최대 부하량을 확인하는 스트레스 테스트

#### 테스트 결과

스크립트를 실행하여 점진적으로 부하를 높인 결과, **초당 요청 수(RPS)가 약 163에 도달했을 때** 서버의 응답이 급격히 느려지다가 결국 다운되는 현상이 발생했다.

#### 결과 분석: '163 RPS'는 어느 정도 수준인가?

'초당 163개의 요청'에서 시스템의 한계점을 발견했다는 것은 **매우 의미 있고 성공적인 스트레스 테스트 결과**다. 이 수치가 갖는 의미를 여러 관점에서 분석할 수 있다.

**1. 절대적인 처리량 관점**

`163 RPS`라는 수치는 잘 구축된 웹 서비스의 견고한 성능을 보여주는 지표다. 이 처리량을 다른 시간 단위로 환산해 보면 규모를 더 쉽게 체감할 수 있다.

* **분당 처리량:** 163 RPS \* 60초 = **약 9,780 RPM**
* **시간당 처리량:** 9,780 RPM \* 60분 = **약 58만 요청**
* **일일 처리량:** 약 58만 \* 24시간 = **약 1,400만 요청**

163 RPS를 분당 처리량으로 환산하면 약 9,780 RPM에 해당한다. 이는 일반적인 데스크탑 사양의 서버 환경으로도 최적화를 통해 활성 사용자를 보유한 서비스의 트래픽을 충분히 감당할 수 있는 잠재력을 보여주는 유의미한 수치다. 또한 신기하게도 이 테스트를 통해, 복잡한 비즈니스 로직이 없음에도 Spring Boot 프레임워크 자체가 가진 기본 동작만으로도 순수한 Netty/TCP 서버 등에 비해 처리량이 자연스럽게 낮아진다는 점을 확인할 수 있었다.

**2. 환경적 관점**

* **하드웨어 및 프레임워크:** 강력한 성능의 Ryzen 7 5800X CPU와 Spring Boot 프레임워크 조합으로 초당 160개 이상의 요청을 처리한 것은, 애플리케이션의 비즈니스 로직이 효율적으로 구성되었음을 보여주는 긍정적인 신호다.
* **네트워크 지연 시간 (Ping 65ms):** 이 테스트는 내부망이 아닌, 실제 외부 사용자와 유사한 65ms의 네트워크 지연 시간을 포함한 결과다. 이는 서버의 순수 처리 성능뿐만 아니라 실제 서비스 환경에서의 성능을 검증했다는 점에서 높은 신뢰도를 가진다.

**3. 최종 결론**

이 테스트 결과는 '오몰리' 서비스에 대한 다음과 같은 명확한 기준을 제공한다.

* **명확한 한계점 설정:** 우리 시스템의 성능 한계는 약 **160 ~ 170 RPS** 구간이다. 이 이상의 트래픽이 예상되는 대규모 이벤트 시에는 반드시 서버 증설(Scale-out)과 같은 대비책이 필요하다.

* **데이터 기반의 성능 근거:** 막연히 '빠르다'가 아니라, "우리 서버는 외부망 기준으로 초당 약 160개의 요청을 안정적으로 처리할 수 있다"고 구체적인 데이터로 성능을 증명할 수 있다.

* **운영 모니터링 기준 수립:** 운영 중인 서버의 RPS가 **100 ~ 120 (임계치의 70~80%)** 에 도달하면, 이를 위험 신호로 간주하고 알림을 발생시켜 장애를 사전에 예방하는 구체적인 기준을 세울 수 있다.

---

### 6. 심화 학습

  * **병목 지점 분석 도구**: 부하 테스트 시 함께 사용하면 원인 분석이 훨씬 쉬워진다.
      * **APM (Application Performance Monitoring)**: Pinpoint, Scouter, Datadog 등은 트랜잭션 흐름을 추적하여 어느 함수, 어느 쿼리에서 시간이 오래 걸리는지 시각적으로 보여준다.
  * **결과 리포트 작성**: 테스트 결과는 모두가 이해할 수 있도록 명확하게 정리해야 한다.
      * **핵심 요약(Key Takeaways)**, **시각화 자료(그래프)**, **개선 제안**을 포함하여 작성한다.
  * **CI/CD 파이프라인 연동**: 코드 변경 시(예: Pull Request) 자동으로 성능 테스트를 실행하여 성능 저하를 조기에 발견하는 '성능 게이트'를 구축할 수 있다.

-----

### 7. 마무리

  * **핵심 요약**
    1.  부하 테스트는 장애를 예방하고 서비스 안정성을 확보하는 선제적 활동이다.
    2.  응답 시간, 처리량, 에러율은 성능을 판단하는 핵심 지표다.
    3.  부하 테스트는 '목표 설정 → 시나리오 설계 → 실행 → 분석 → 개선'의 반복적인 프로세스다.
    4.  k6와 같은 도구를 통해 개발자도 쉽게 부하 테스트를 수행할 수 있다.

