# AOP ì ìš©í–ˆëŠ”ë° ì½”ë“œê°€ ë” ëŠ˜ì–´ë‚¬ìŠµë‹ˆë‹¤

# AOPê°€ ë¬´ì—‡ì¸ê°€ - "ì½”ë“œ ì¤‘ë³µì„ ì—†ì• ëŠ” ë˜‘ë˜‘í•œ ë°©ë²•"

```bash
ğŸ“ AOP í•œ ì¤„ ì •ì˜
"ëª¨ë“  í•¨ìˆ˜ì— ê³µí†µìœ¼ë¡œ í•„ìš”í•œ ì½”ë“œë¥¼ í•œ ê³³ì— ëª¨ì•„ì„œ ìë™ìœ¼ë¡œ ì ìš©í•˜ëŠ” ê¸°ë²•"

ğŸ“ ê°„ë‹¨í•œ Before/After
Before: ë¡œê¹… ì½”ë“œë¥¼ 10ê°œ í•¨ìˆ˜ì— ë³µì‚¬-ë¶™ì—¬ë„£ê¸°
After: @log ë°ì½”ë ˆì´í„° í•˜ë‚˜ë¡œ í•´ê²°

ğŸ“ í•µì‹¬ ê°œë… 2ê°€ì§€ë§Œ
- í•µì‹¬ ê´€ì‹¬ì‚¬: í•¨ìˆ˜ê°€ ì§„ì§œ í•˜ë ¤ëŠ” ì¼
- íš¡ë‹¨ ê´€ì‹¬ì‚¬: ëª¨ë“  í•¨ìˆ˜ì— ê³µí†µìœ¼ë¡œ í•„ìš”í•œ ì¼
```

# ì‹¤ì œ ê°œë°œí•  ë•Œ ê²ªëŠ” ë¬¸ì œ

```bash
ğŸ“… 1ì£¼ì°¨: "ê°„ë‹¨í•œ í¬ë¡¤ëŸ¬ ë§Œë“¤ì–´ì£¼ì„¸ìš”"
def crawl_data():
    return requests.get("...")

ğŸ˜Š "ì‰½ë„¤!"

ğŸ“… 2ì£¼ì°¨: íŒ€ì¥ "ë¡œê·¸ ì¢€ ë‚¨ê²¨ì£¼ì„¸ìš”"  
def crawl_data():
    print("ì‹œì‘")
    result = requests.get("...")
    print("ì™„ë£Œ")
    return result

ğŸ˜ "ìŒ... ê´œì°®ë„¤"

ğŸ“… 3ì£¼ì°¨: íŒ€ì¥ "ì—ëŸ¬ ì²˜ë¦¬ë„ í•´ì£¼ì„¸ìš”"
def crawl_data():
    print("ì‹œì‘")
    try:
        result = requests.get("...")
        print("ì™„ë£Œ")
        return result
    except Exception as e:
        print(f"ì—ëŸ¬: {e}")
        return None

ğŸ˜• "ì½”ë“œê°€ ì¢€ ë³µì¡í•´ì§€ë„¤..."

ğŸ“… 4ì£¼ì°¨: íŒ€ì¥ "ì„±ëŠ¥ ì¸¡ì •ë„ ì¶”ê°€í•´ì£¼ì„¸ìš”"
ğŸ“… 5ì£¼ì°¨: íŒ€ì¥ "ì¬ì‹œë„ ë¡œì§ë„ ë„£ì–´ì£¼ì„¸ìš”"  
ğŸ“… 6ì£¼ì°¨: íŒ€ì¥ "ìºì‹±ë„ í•´ì£¼ì„¸ìš”"

ğŸ˜± "20ì¤„ ì¤‘ì— í•µì‹¬ ë¡œì§ì€ 1ì¤„ë¿ì´ì•¼!"

ğŸ“… 7ì£¼ì°¨: íŒ€ì¥ "í¬ë¡¤ëŸ¬ 10ê°œ ë” ë§Œë“¤ì–´ì£¼ì„¸ìš”"

ğŸ¤¯ "ì´ ì½”ë“œë¥¼ 10ë²ˆ ë³µì‚¬ë¶™ì—¬ë„£ê¸°?!"

ğŸ“… 8ì£¼ì°¨: ë²„ê·¸ ë°œê²¬
ğŸ‘¨â€ğŸ’¼ "10ê°œ íŒŒì¼ ë‹¤ ê³ ì³ì•¼ í•´ìš”..."

ğŸ˜­ "ì§€ì˜¥ì´ë‹¤..."
```

# ì´ë•Œ AOPë¥¼ ì•Œì•˜ë‹¤ë©´?

```python
# 8ì£¼ê°„ì˜ ê³ ìƒì´ ì´ë ‡ê²Œ ê°„ë‹¨í•´ì§
@log @retry @performance @cache
def crawl_data():
    return requests.get("...")

# ìƒˆ í¬ë¡¤ëŸ¬ ì¶”ê°€ë„ 2ì¤„ë¡œ ë
@log @retry @performance @cache  
def crawl_new_site():
    return requests.get("...")
```

# ë‚´ í”„ë¡œì íŠ¸ì— ì ìš©í•œë‹¤ë©´? 

```bash
ğŸ¯ ë°ë¸Œìº˜ í”„ë¡œì íŠ¸ ëª©í‘œ
"ê°œë°œì í–‰ì‚¬ ì •ë³´ë¥¼ ì—¬ëŸ¬ ì‚¬ì´íŠ¸ì—ì„œ ìˆ˜ì§‘í•´ì„œ ê°œì¸ ë§ì¶¤í˜• ìº˜ë¦°ë”ë¡œ ì œê³µ"

âœ… ê°œë°œ íë¦„
1ë‹¨ê³„(í˜„ì¬): ì˜¨ì˜¤í”„ë¯¹ìŠ¤ 1í˜ì´ì§€ë§Œ (20ê°œ í–‰ì‚¬)
   â†“
2ë‹¨ê³„: ì „ì²´ í˜ì´ì§€ í¬ë¡¤ë§ (20+ê°œ í–‰ì‚¬, Playwright ë„ì…)
   â†“ 
3ë‹¨ê³„: Claudeë¡œ ìë™ íŒŒì‹±
   â†“    
4ë‹¨ê³„: ì´ë²¤í„°ìŠ¤ ì¶”ê°€
   â†“   
5ë‹¨ê³„: ë§í¬ë“œì¸ ì¶”ê°€
   â†“   
ë§ˆì§€ì§€ë§‰: ì—¬ëŸ¬ ì‚¬ì´íŠ¸ í†µí•© í”Œë«í¼ ì™„ì„±

ğŸš¨ ì˜ˆìƒë˜ëŠ” ë¬¸ì œë“¤ 
í˜„ì¬: ì˜¨ì˜¤í”„ë¯¹ìŠ¤ í¬ë¡¤ëŸ¬ (requestsë§Œ)
1. Playwright ë„ì… (ğŸ˜± í•µì‹¬ ë¡œì§ 1ì¤„, ë¶€ê°€ ì½”ë“œ Nì¤„!)
2. Claude API ì¶”ê°€ (ğŸ˜± ì´ Nì¤„ ì¤‘ í•µì‹¬ ë¡œì§ ì—¬ì „íˆ 1ì¤„!)
3. ì‚¬ì´íŠ¸ ì¶”ê°€ (ğŸ˜± ë™ì¼í•œ ì½”ë“œì—ì„œ URL 3ê°œë§Œ ë‹¤ë¦„!)
4. Playwright ì—ëŸ¬ ë°œê²¬ (ğŸ˜± ë²„ê·¸ ìˆ˜ì • ì§€ì˜¥ì— ë¹ ì§„ë‹¤)
â†’ ê°œ íŒŒì¼ ëª¨ë‘ ìˆ˜ì •í•´ì•¼ í•¨
â†’ í•˜ë‚˜ë¼ë„ ë¹ ëœ¨ë¦¬ë©´ ë²„ê·¸ ë‚¨ì•„ìˆìŒ
â†’ ì¼ê´€ì„± ê¹¨ì§
ğŸ˜­ "ê°™ì€ ë²„ê·¸ë¥¼ 3ë²ˆ ê³ ì³ì•¼ í•´ìš”..."
```

# AOP ì ìš© ì‹œë‚˜ë¦¬ì˜¤

## í˜„ì¬ ì½”ë“œ (requestsë§Œ ì‚¬ìš©)

```python
# onoffmix_crawler.py (í˜„ì¬ ì½”ë“œ)
import requests
from bs4 import BeautifulSoup

# ì˜¨ì˜¤í”„ë¯¹ìŠ¤ AI ê´€ë ¨ í–‰ì‚¬ ê²€ìƒ‰ URL
url = "https://onoffmix.com/event/main?s=%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%20ai%20chatgpt%20%EC%B1%97gpt"

# ë¸Œë¼ìš°ì €ì¸ ì²™ í•˜ê¸° ìœ„í•œ í—¤ë” ì„¤ì •
headers = {
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
}

# HTTP GET ìš”ì²­ìœ¼ë¡œ HTML ê°€ì ¸ì˜¤ê¸°
response = requests.get(url, headers=headers)

# HTMLì„ BeautifulSoupìœ¼ë¡œ íŒŒì‹± ê°€ëŠ¥í•œ ê°ì²´ë¡œ ë³€í™˜
soup = BeautifulSoup(response.text, 'html.parser')

# CSS ì„ íƒìë¡œ ëª¨ë“  í–‰ì‚¬ ì¹´ë“œ ì°¾ê¸°
events = soup.select('article.event_area.event_main')

print(f"ì´ {len(events)}ê°œì˜ í–‰ì‚¬ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤!")

# ì¶”ì¶œëœ í–‰ì‚¬ ì •ë³´ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
all_events = []

# ê° í–‰ì‚¬ ì¹´ë“œì—ì„œ ì •ë³´ ì¶”ì¶œ
for i, event in enumerate(events):
    try:
        # í–‰ì‚¬ ì œëª© ì¶”ì¶œ
        title = event.find('h5', class_='title ellipsis').text.strip()
        
        # ê°€ê²© ì •ë³´ ì¶”ì¶œ (ë¬´ë£Œ/ìœ ë£Œ)
        payment = event.find('span', class_='payment_type').text.strip()
        
        # í–‰ì‚¬ ë‚ ì§œ ì¶”ì¶œ
        date = event.find('div', class_='date').text.strip()
        
        # í–‰ì‚¬ ì¥ì†Œ/ì§€ì—­ ì¶”ì¶œ
        place = event.find('span', class_='place').text.strip()
        
        # ìƒì„¸ í˜ì´ì§€ ë§í¬ ì¶”ì¶œ (ìƒëŒ€ ê²½ë¡œ)
        link = event.find('a')['href']
        
        # ì¶”ì¶œëœ ì •ë³´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ êµ¬ì¡°í™”
        event_data = {
            "id": i + 1,
            "title": title,
            "payment": payment,
            "date": date,
            "place": place,
            "link": "https://onoffmix.com" + link  # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
        }
        
        # ë¦¬ìŠ¤íŠ¸ì— í–‰ì‚¬ ì •ë³´ ì¶”ê°€
        all_events.append(event_data)
        
        # ì½˜ì†”ì— ê°„ë‹¨í•œ ì •ë³´ ì¶œë ¥
        print(f"{i+1}. {title} | {payment} | {place}")
        
    except Exception as e:
        # íŠ¹ì • í–‰ì‚¬ íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë¡œê·¸
        print(f"í–‰ì‚¬ {i+1} ì¶”ì¶œ ì‹¤íŒ¨: {e}")

# ìµœì¢… ê²°ê³¼ ì¶œë ¥
print(f"\nì´ {len(all_events)}ê°œ í–‰ì‚¬ ì¶”ì¶œ ì™„ë£Œ!")
```

**ê²°ê³¼:**

- ì•½ 20ê°œ í–‰ì‚¬ (1í˜ì´ì§€ë§Œ)

# Playwright ë„ì… í›„ (AOP ì—†ìŒ)

```python
# onoffmix_playwright_crawler.py (Playwright ë„ì… í›„)
import requests
from bs4 import BeautifulSoup
from playwright.sync_api import sync_playwright

def crawl_with_playwright():
    # ì˜¨ì˜¤í”„ë¯¹ìŠ¤ AI ê´€ë ¨ í–‰ì‚¬ ê²€ìƒ‰ URL
    url = "https://onoffmix.com/event/main?s=%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%20ai%20chatgpt%20%EC%B1%97gpt"
    
    # Playwright ë¸Œë¼ìš°ì € ì„¤ì • ì‹œì‘
    with sync_playwright() as p:
        # í¬ë¡œë¯¸ì›€ ë¸Œë¼ìš°ì € ì‹¤í–‰ (í™”ë©´ ì•ˆ ë³´ì´ê²Œ)
        browser = p.chromium.launch(headless=True)
        
        # ìƒˆ í˜ì´ì§€ ìƒì„±
        page = browser.new_page()
        
        # ë¸Œë¼ìš°ì € í—¤ë” ì„¤ì • (ë´‡ ì°¨ë‹¨ ìš°íšŒ)
        page.set_extra_http_headers({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        })
        
        # ì²« í˜ì´ì§€ë¡œ ì´ë™
        page.goto(url)
        
        # í˜ì´ì§€ ë¡œë”© ì™„ë£Œê¹Œì§€ ëŒ€ê¸°
        page.wait_for_load_state()
        
        # ëª¨ë“  í˜ì´ì§€ì˜ í–‰ì‚¬ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
        all_page_events = []
        
        # í˜ì´ì§€ë„¤ì´ì…˜ ì²˜ë¦¬: 1-5í˜ì´ì§€ ìˆœíšŒ
        for page_num in range(1, 6):
            try:
                print(f"ğŸ“„ {page_num}í˜ì´ì§€ ì²˜ë¦¬ ì¤‘...")
                
                # 2í˜ì´ì§€ë¶€í„°ëŠ” í˜ì´ì§€ ë²„íŠ¼ í´ë¦­
                if page_num > 1:
                    # í˜ì´ì§€ ë²ˆí˜¸ ë²„íŠ¼ í´ë¦­
                    page.click(f'[data-page="{page_num}"]')
                    
                    # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸° (2ì´ˆ)
                    page.wait_for_timeout(2000)
                    
                    # í˜ì´ì§€ ë¡œë”© ì™„ë£Œê¹Œì§€ ëŒ€ê¸°
                    page.wait_for_load_state()
                
                # í˜„ì¬ í˜ì´ì§€ì˜ ì™„ì „í•œ HTML ê°€ì ¸ì˜¤ê¸°
                html_content = page.content()
                
                # HTMLì„ BeautifulSoupìœ¼ë¡œ íŒŒì‹±
                soup = BeautifulSoup(html_content, 'html.parser')
                
                # í˜„ì¬ í˜ì´ì§€ì˜ ëª¨ë“  í–‰ì‚¬ ì¹´ë“œ ì°¾ê¸°
                events = soup.select('article.event_area.event_main')
                
                print(f"  â†’ {len(events)}ê°œ í–‰ì‚¬ ë°œê²¬")
                
                # í˜„ì¬ í˜ì´ì§€ì˜ ê° í–‰ì‚¬ ì •ë³´ ì¶”ì¶œ
                for i, event in enumerate(events):
                    try:
                        # í–‰ì‚¬ ì œëª© ì¶”ì¶œ
                        title = event.find('h5', class_='title ellipsis').text.strip()
                        
                        # ê°€ê²© ì •ë³´ ì¶”ì¶œ
                        payment = event.find('span', class_='payment_type').text.strip()
                        
                        # í–‰ì‚¬ ë‚ ì§œ ì¶”ì¶œ
                        date = event.find('div', class_='date').text.strip()
                        
                        # í–‰ì‚¬ ì¥ì†Œ ì¶”ì¶œ
                        place = event.find('span', class_='place').text.strip()
                        
                        # ìƒì„¸ í˜ì´ì§€ ë§í¬ ì¶”ì¶œ
                        link = event.find('a')['href']
                        
                        # í–‰ì‚¬ ì •ë³´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ êµ¬ì¡°í™”
                        event_data = {
                            "id": len(all_page_events) + i + 1,  # ì „ì²´ ë¦¬ìŠ¤íŠ¸ ê¸°ì¤€ ID
                            "title": title,
                            "payment": payment,
                            "date": date,
                            "place": place,
                            "link": "https://onoffmix.com" + link,  # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
                            "page": page_num  # ì–´ëŠ í˜ì´ì§€ì—ì„œ ê°€ì ¸ì™”ëŠ”ì§€ ê¸°ë¡
                        }
                        
                        # ì „ì²´ í–‰ì‚¬ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                        all_page_events.append(event_data)
                        
                    except Exception as e:
                        # ê°œë³„ í–‰ì‚¬ íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë¡œê·¸
                        print(f"    í–‰ì‚¬ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                
            except Exception as e:
                # í˜ì´ì§€ ì²˜ë¦¬ ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë¡œê·¸ ë° ì¤‘ë‹¨
                print(f"âŒ {page_num}í˜ì´ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                break
        
        # ë¸Œë¼ìš°ì € ì¢…ë£Œ ë° ìì› ì •ë¦¬
        browser.close()
        
    # ëª¨ë“  í˜ì´ì§€ì˜ í–‰ì‚¬ ì •ë³´ ë°˜í™˜
    return all_page_events

# ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„
if __name__ == "__main__":
    # Playwright í¬ë¡¤ë§ ì‹¤í–‰
    all_events = crawl_with_playwright()
    
    # ìµœì¢… ê²°ê³¼ ì¶œë ¥
    print(f"\nğŸ‰ ì´ {len(all_events)}ê°œ í–‰ì‚¬ ì¶”ì¶œ ì™„ë£Œ!")
    
    # í˜ì´ì§€ë³„ í†µê³„ ê³„ì‚°
    page_stats = {}
    for event in all_events:
        page = event['page']
        if page not in page_stats:
            page_stats[page] = 0
        page_stats[page] += 1
    
    # í˜ì´ì§€ë³„ ìˆ˜ì§‘ ê²°ê³¼ ì¶œë ¥
    for page, count in page_stats.items():
        print(f"  {page}í˜ì´ì§€: {count}ê°œ")
```

ë¬¸ì œì : 

- ê¸°ì¡´ 40ì¤„ â†’ 93ì¤„ë¡œ ì¦ê°€ ğŸ˜±
- í•µì‹¬ ë¡œì§(íŒŒì‹±)ì€ ê·¸ëŒ€ë¡œì¸ë° ë¸Œë¼ìš°ì € ê´€ë¦¬ ì½”ë“œê°€ 53ì¤„ ì¶”ê°€
- ë³µì¡ì„± 3.5ë°° ì¦ê°€

# AOP ì ìš© í›„

### 1. Aspect ìƒì„±

```python
# aspects/playwright_aspect.py
import functools
from playwright.sync_api import sync_playwright
from bs4 import BeautifulSoup

class PlaywrightAspect:
    @staticmethod
    def browser_management(func):
        """ë¸Œë¼ìš°ì € ìƒì„±/ê´€ë¦¬ë¥¼ ìë™í™”í•˜ëŠ” ë°ì½”ë ˆì´í„°"""
        @functools.wraps(func)
        def wrapper(url, *args, **kwargs):
            # Playwright ì»¨í…ìŠ¤íŠ¸ ì‹œì‘
            with sync_playwright() as p:
                # í¬ë¡œë¯¸ì›€ ë¸Œë¼ìš°ì € ì‹¤í–‰ (ë°±ê·¸ë¼ìš´ë“œ)
                browser = p.chromium.launch(headless=True)
                
                # ìƒˆ í˜ì´ì§€ ìƒì„±
                page = browser.new_page()
                
                # ë´‡ ì°¨ë‹¨ ìš°íšŒë¥¼ ìœ„í•œ User-Agent ìë™ ì„¤ì •
                page.set_extra_http_headers({
                    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
                })
                
                try:
                    # ì‹¤ì œ í•¨ìˆ˜ ì‹¤í–‰ (page ê°ì²´ë¥¼ í•¨ìˆ˜ì— ì „ë‹¬)
                    result = func(page, url, *args, **kwargs)
                    return result
                finally:
                    # ì„±ê³µ/ì‹¤íŒ¨ ê´€ê³„ì—†ì´ ë¸Œë¼ìš°ì € ì •ë¦¬
                    browser.close()
                    print("ğŸ”’ ë¸Œë¼ìš°ì € ì •ë¦¬ ì™„ë£Œ")
        return wrapper
    
    @staticmethod
    def navigate_pages(max_pages=5):
        """í˜ì´ì§€ë„¤ì´ì…˜ ìë™ ì²˜ë¦¬ ë°ì½”ë ˆì´í„°"""
        def decorator(func):
            @functools.wraps(func)
            def wrapper(page, url, *args, **kwargs):
                # ì²« í˜ì´ì§€ë¡œ ì´ë™
                page.goto(url)
                
                # í˜ì´ì§€ ë¡œë”© ì™„ë£Œ ëŒ€ê¸°
                page.wait_for_load_state()
                
                # ëª¨ë“  í˜ì´ì§€ ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
                all_results = []
                
                # ì§€ì •ëœ í˜ì´ì§€ ìˆ˜ë§Œí¼ ìˆœíšŒ
                for page_num in range(1, max_pages + 1):
                    try:
                        print(f"ğŸ“„ {page_num}í˜ì´ì§€ ì²˜ë¦¬ ì¤‘...")
                        
                        # 2í˜ì´ì§€ë¶€í„°ëŠ” í˜ì´ì§€ ë²„íŠ¼ í´ë¦­
                        if page_num > 1:
                            # í˜ì´ì§€ ë²ˆí˜¸ì— í•´ë‹¹í•˜ëŠ” ë²„íŠ¼ í´ë¦­
                            page.click(f'[data-page="{page_num}"]')
                            
                            # JavaScript ì‹¤í–‰ ë° ë¡œë”© ëŒ€ê¸°
                            page.wait_for_timeout(2000)
                            
                            # í˜ì´ì§€ ë¡œë”© ì™„ë£Œ ëŒ€ê¸°
                            page.wait_for_load_state()
                        
                        # í˜„ì¬ í˜ì´ì§€ ì²˜ë¦¬ (ì‹¤ì œ í•¨ìˆ˜ í˜¸ì¶œ)
                        result = func(page, page_num, *args, **kwargs)
                        
                        # ê²°ê³¼ë¥¼ ì „ì²´ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                        all_results.extend(result)
                        
                    except Exception as e:
                        # í˜ì´ì§€ ì²˜ë¦¬ ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë¡œê·¸ ë° ì¤‘ë‹¨
                        print(f"âŒ {page_num}í˜ì´ì§€ ì‹¤íŒ¨: {e}")
                        break
                
                # ëª¨ë“  í˜ì´ì§€ ê²°ê³¼ ë°˜í™˜
                return all_results
            return wrapper
        return decorator
```

### 2. ì ìš©ëœ í¬ë¡¤ëŸ¬

```python
# onoffmix_aop_crawler.py (AOP ì ìš©)
from bs4 import BeautifulSoup
from aspects.playwright_aspect import PlaywrightAspect

# Playwright ê´€ë ¨ ëª¨ë“  ì‘ì—…ì„ Aspectê°€ ìë™ ì²˜ë¦¬
@PlaywrightAspect.browser_management
@PlaywrightAspect.navigate_pages(max_pages=5)
def crawl_onoffmix_events(page, page_num):
    """í•µì‹¬ ë¡œì§: í˜„ì¬ í˜ì´ì§€ì—ì„œ í–‰ì‚¬ ì •ë³´ ì¶”ì¶œ"""
    
    # í˜„ì¬ í˜ì´ì§€ì˜ ì™„ì „í•œ HTML ê°€ì ¸ì˜¤ê¸°
    html_content = page.content()
    
    # HTMLì„ BeautifulSoupìœ¼ë¡œ íŒŒì‹±
    soup = BeautifulSoup(html_content, 'html.parser')
    
    # í˜„ì¬ í˜ì´ì§€ì˜ ëª¨ë“  í–‰ì‚¬ ì¹´ë“œ ì°¾ê¸°
    events = soup.select('article.event_area.event_main')
    
    print(f"  â†’ {len(events)}ê°œ í–‰ì‚¬ ë°œê²¬")
    
    # í˜„ì¬ í˜ì´ì§€ì˜ í–‰ì‚¬ ì •ë³´ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    page_events = []
    
    # ê° í–‰ì‚¬ ì¹´ë“œì—ì„œ ì •ë³´ ì¶”ì¶œ (ê¸°ì¡´ ë¡œì§ê³¼ ë™ì¼)
    for i, event in enumerate(events):
        try:
            # í–‰ì‚¬ ì œëª© ì¶”ì¶œ
            title = event.find('h5', class_='title ellipsis').text.strip()
            
            # ê°€ê²© ì •ë³´ ì¶”ì¶œ
            payment = event.find('span', class_='payment_type').text.strip()
            
            # í–‰ì‚¬ ë‚ ì§œ ì¶”ì¶œ
            date = event.find('div', class_='date').text.strip()
            
            # í–‰ì‚¬ ì¥ì†Œ ì¶”ì¶œ
            place = event.find('span', class_='place').text.strip()
            
            # ìƒì„¸ í˜ì´ì§€ ë§í¬ ì¶”ì¶œ
            link = event.find('a')['href']
            
            # í–‰ì‚¬ ì •ë³´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ êµ¬ì¡°í™”
            event_data = {
                "id": f"{page_num}-{i+1}",  # í˜ì´ì§€-ìˆœì„œ í˜•íƒœì˜ ID
                "title": title,
                "payment": payment,
                "date": date,
                "place": place,
                "link": "https://onoffmix.com" + link,  # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
                "page": page_num  # í˜ì´ì§€ ë²ˆí˜¸ ê¸°ë¡
            }
            
            # í˜„ì¬ í˜ì´ì§€ í–‰ì‚¬ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
            page_events.append(event_data)
            
        except Exception as e:
            # ê°œë³„ í–‰ì‚¬ íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë¡œê·¸
            print(f"    í–‰ì‚¬ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
    
    # í˜„ì¬ í˜ì´ì§€ì˜ ëª¨ë“  í–‰ì‚¬ ì •ë³´ ë°˜í™˜
    return page_events

# ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„
if __name__ == "__main__":
    # ì˜¨ì˜¤í”„ë¯¹ìŠ¤ AI ê´€ë ¨ í–‰ì‚¬ ê²€ìƒ‰ URL
    url = "https://onoffmix.com/event/main?s=%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%20ai%20chatgpt%20%EC%B1%97gpt"
    
    # AOPê°€ ì ìš©ëœ í¬ë¡¤ë§ ì‹¤í–‰ (ë¸Œë¼ìš°ì € ê´€ë¦¬, í˜ì´ì§€ë„¤ì´ì…˜ ìë™ ì²˜ë¦¬)
    all_events = crawl_onoffmix_events(url)
    
    # ìµœì¢… ê²°ê³¼ ì¶œë ¥
    print(f"\nğŸ‰ ì´ {len(all_events)}ê°œ í–‰ì‚¬ ì¶”ì¶œ ì™„ë£Œ!")
    
    # í˜ì´ì§€ë³„ í†µê³„ ê³„ì‚°
    page_stats = {}
    for event in all_events:
        page = event['page']
        if page not in page_stats
```

# ê²°ê³¼ ë¹„êµ 

### **ì½”ë“œëŸ‰ ë¹„êµ**

```other
í˜„ì¬ (requests): 66ì¤„
Playwright ë„ì… (AOP ì—†ìŒ): 124ì¤„ (+58ì¤„)
Playwright ë„ì… (AOP ì ìš©): 80ì¤„ + 79ì¤„ = 159ì¤„ (+35ì¤„)

ğŸ˜± AOP ì ìš©í–ˆëŠ”ë° 35ì¤„ì´ ë” ëŠ˜ì–´ë‚¬ë„¤ìš”!
```

### **ë³µì¡ë„ ë¹„êµ**

```other
AOP ì—†ìŒ: ë¸Œë¼ìš°ì € ê´€ë¦¬ + í˜ì´ì§€ë„¤ì´ì…˜ + íŒŒì‹± ë¡œì§ ëª¨ë‘ ì„ì„
AOP ì ìš©: íŒŒì‹± ë¡œì§ë§Œ ì§‘ì¤‘, ë‚˜ë¨¸ì§€ëŠ” Aspectê°€ ì²˜ë¦¬
```

### **ìœ ì§€ë³´ìˆ˜ì„±**

```other
AOP ì—†ìŒ: ë¸Œë¼ìš°ì € ì—ëŸ¬ ì‹œ 70ì¤„ ì½”ë“œ ì „ì²´ ë””ë²„ê¹…
AOP ì ìš©: ë¸Œë¼ìš°ì € ì—ëŸ¬ ì‹œ Aspectë§Œ ìˆ˜ì •í•˜ë©´ ë¨
```

# AOPê°€ ì–¸ì œ ì˜ë¯¸ ìˆëŠ”ê°€? 

#### 1. **ë‹¨ì¼ ì‚¬ì´íŠ¸ í¬ë¡¤ëŸ¬**

```other
ì‚¬ì´íŠ¸ 1ê°œë§Œ í¬ë¡¤ë§ â†’ ì½”ë“œ ì¬ì‚¬ìš© ì—†ìŒ
â†’ AOP ë„ì… = ë¶ˆí•„ìš”í•œ ë³µì¡ì„± ì¶”ê°€
```

#### 2. **ì‘ì€ í”„ë¡œì íŠ¸**

```other
ì´ ì½”ë“œ 100ì¤„ ë¯¸ë§Œ â†’ êµ¬ì¡°í™”í•  í•„ìš” ì—†ìŒ
â†’ AOP = ê³¼ë„í•œ ì•„í‚¤í…ì²˜
```

# í•˜ì§€ë§Œ! ì‚¬ì´íŠ¸ê°€ ëŠ˜ì–´ë‚˜ë©´...? ğŸš€

#### **AOP ì—†ìŒ**

```other
ì˜¨ì˜¤í”„ë¯¹ìŠ¤: 124ì¤„
ì´ë²¤í„°ìŠ¤: 124ì¤„ (ê±°ì˜ ë™ì¼í•œ ì½”ë“œ ë³µì‚¬)
ë§í¬ë“œì¸: 124ì¤„ (ë˜ ê±°ì˜ ë™ì¼í•œ ì½”ë“œ ë³µì‚¬)
ì´í•©: 372ì¤„ (ì¤‘ë³µ ì½”ë“œ ì²œêµ­)
```

#### **AOP ì ìš©**

```other
Aspect: 80ì¤„ (í•œ ë²ˆë§Œ ì‘ì„±)
ì˜¨ì˜¤í”„ë¯¹ìŠ¤: 79ì¤„
ì´ë²¤í„°ìŠ¤: 79ì¤„  
ë§í¬ë“œì¸: 79ì¤„
ì´í•©: 317ì¤„ (55ì¤„ ì ˆì•½)
```

### **5ê°œ ì‚¬ì´íŠ¸ ì¶”ê°€ ì‹œ**

```other
AOP ì—†ìŒ: 124 Ã— 5 = 620ì¤„
AOP ì ìš©: 80 + (79 Ã— 5) = 475ì¤„ (145ì¤„ ì ˆì•½, 23% ì ˆì•½)
```

# AOPì˜ í˜„ì‹¤ì ì¸ í•œê³„

```other
ğŸš¨ ì†”ì§í•œ ê³ ë°±:
"1ê°œ ì‚¬ì´íŠ¸ë§Œ í¬ë¡¤ë§í•œë‹¤ë©´ AOPëŠ” ì˜¤ë²„ì—”ì§€ë‹ˆì–´ë§ì…ë‹ˆë‹¤!"

âœ… AOPê°€ ìœ ìš©í•œ ê²½ìš°:
- 3ê°œ ì´ìƒ ì‚¬ì´íŠ¸ í¬ë¡¤ë§
- íŒ€ í”„ë¡œì íŠ¸ (ì—¬ëŸ¬ ê°œë°œì)
- ì¥ê¸° ìœ ì§€ë³´ìˆ˜ í•„ìš”

âŒ AOPê°€ ë¶ˆí•„ìš”í•œ ê²½ìš°:  
- 1-2ê°œ ì‚¬ì´íŠ¸ë§Œ
- ì¼íšŒì„± í”„ë¡œì íŠ¸
- ê°œì¸ í”„ë¡œì íŠ¸
```

# **ì ì • ê¸°ìˆ  ì„ íƒì˜ ì¤‘ìš”ì„±**

```other
ğŸ’­ ê°œë°œìì˜ ê³ ë¯¼:
"ì§€ê¸ˆ AOPë¥¼ ë„ì…í• ê¹Œ? ë‚˜ì¤‘ì— ë„ì…í• ê¹Œ?"

ğŸ“ˆ í˜„ì‹¤ì ì¸ íŒë‹¨ ê¸°ì¤€:
- í˜„ì¬: 1ê°œ ì‚¬ì´íŠ¸ â†’ AOP ë¶ˆí•„ìš”
- 2-3ê°œ ì‚¬ì´íŠ¸ ê³„íš â†’ AOP ê³ ë ¤
- 5ê°œ+ ì‚¬ì´íŠ¸ ê³„íš â†’ AOP í•„ìˆ˜
```

# ê²°ë¡ 

- â€œë‚´ í”„ë¡œì íŠ¸ì—ì„œ í¬ë¡¤ë§í•  ì‚¬ì´íŠ¸ê°€ ëª‡ ê°œì¸ê°€?â€
- ì‚¬ì´íŠ¸ ê°œìˆ˜ ë¨¼ì € íŒŒì•…í•˜ê¸° (í˜„ì¬ ê³„íš + ë¯¸ë˜ í™•ì¥ ê³„íš = ì´ ì˜ˆìƒ ì‚¬ì´íŠ¸ ìˆ˜)

