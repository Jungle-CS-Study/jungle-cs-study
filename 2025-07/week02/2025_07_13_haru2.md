
## 분산 처리 시스템 관점에서 바라본 멀티스레드 처리

### 📌 서론: '빠름'은 무엇을 의미하는가?

우리는 흔히 컴퓨터가 빠르다고 이야기하지만, 이 '빠름'은 사용하는 목적에 따라 다르게 해석된다. 개인용 데스크톱은 **즉각적인 사용자 응답성**을 중요하게 여기는 반면, 서버나 클러스터 시스템은 수많은 요청을 **안정적으로 처리하는 처리량과 병렬성**을 핵심 가치로 둔다.

이러한 '빠름'의 차이는 궁극적으로 **작업을 어떤 단위로 나누고, 어떻게 분배하여 처리하는가**에 대한 고민으로 이어진다. 이 자료에서는 멀티코어, 멀티스레드 개념부터 분산 처리 시스템의 대표 주자인 쿠버네티스까지, 프로그램이 작업을 나누어 처리하는 방식을 단계적으로 다뤄보고자 한다.

---

### 🧠 멀티코어와 멀티스레드: 작업 실행의 기본 단위

작업을 나누어 처리하는 가장 기본적인 레벨은 CPU 내부에서 이루어진다.

* **멀티코어(Multi-core)**: CPU 칩 내에 여러 개의 독립적인 실행 유닛인 **코어**가 존재하는 구조이다. 각 코어는 독립적으로 하나의 스레드를 실행할 수 있어 **진정한 의미의 병렬 처리**를 가능하게 한다. 현대의 대부분의 CPU는 멀티코어 구조를 가진다.
* **멀티스레드(Multi-thread)**: 하나의 프로그램이 여러 개의 실행 흐름인 **스레드**를 동시에 생성하여 작업을 처리하는 방식이다. 스레드는 프로세스 내의 독립적인 실행 경로로, 프로세스의 자원(메모리 등)을 공유한다. 프로그램을 멀티스레드로 설계해야만 이러한 병행 또는 병렬 처리가 가능하다.

**💡 핵심:** **스레드**는 작업을 수행하는 논리적인 단위이고, **코어**는 이 스레드를 물리적으로 실행하는 주체이다. 여러 스레드를 여러 코어에 할당함으로써 동시에 많은 작업을 처리할 수 있다.

---

### ⚙️ 일반 프로그램의 작업 처리 방식: 단일 프로세스 관점

대부분의 데스크톱 애플리케이션은 사용자 경험을 중요시하기 때문에 **단일 스레드 기반**으로 설계되는 경우가 많다.

* **즉각적인 UI 응답**: 사용자가 버튼을 클릭하면 즉시 반응해야 한다. 멀티스레드 설계는 복잡성을 증가시키고 동기화 문제 등을 야기할 수 있어, UI 스레드 하나가 모든 이벤트를 처리하는 방식이 선호되기도 한다.
* **설계의 복잡성**: 멀티스레드 프로그램은 데이터 경합(Race Condition), 교착 상태(Deadlock) 등 복잡한 문제를 다루어야 하며, 이는 개발 난이도를 높인다.

이러한 이유로 많은 데스크톱 프로그램은 여전히 **단일 코어 성능**에 크게 의존하며, 데스크톱 CPU는 높은 클럭 속도를 통한 싱글 스레드 성능 향상에 주력해왔다.

#### 캐시 계층과 멀티스레드 효율성

CPU 캐시는 데이터 접근 속도를 높여 성능을 향상시키지만, 멀티스레드 환경에서는 복잡성을 더한다.

* **L1, L2 캐시**: 일반적으로 각 코어에 전용으로 할당된 고속 캐시이다. 해당 코어만 접근할 수 있다.
* **L3 캐시**: 여러 코어가 공유하는 캐시이다. 공유 시 데이터 일관성(Cache Coherency) 유지를 위한 메커니즘이 필요하며, 이는 병목 현상을 유발할 수 있다.

하나의 프로그램을 멀티스레드로 처리할 때, 각 코어는 프로그램이 사용하는 공유 메모리 자원에 접근해야 한다. 코어들은 우선적으로 접근 속도가 빠른 **L1, L2 캐시(약 10사이클 이내)**에 데이터를 저장하고 사용하려 한다. 하지만 공유되는 데이터는 여러 코어에서 동시에 접근하고 변경할 수 있어, 각 코어의 L1/L2 캐시에 있는 데이터가 서로 다를 수 있다. 이러한 **캐시 불일치 문제**가 발생하면, 시스템은 데이터 일관성을 유지하기 위해 **L3 캐시(약 60사이클)**에 접근하거나, 심지어 더 느린 메인 메모리까지 접근하여 데이터를 동기화하는 과정을 거친다. 이 과정에서 발생하는 추가적인 오버헤드가 바로 캐시 효율성을 저해하고 전체적인 멀티스레드 처리 성능을 떨어뜨린다.

---

### 🔍 '쪼개기'의 차이: 실행 단위의 확장

작업을 나누는 방식은 단일 프로그램 내부에만 국한되지 않는다.

* **하나의 실행 파일 내 멀티스레드**: 단일 프로세스 내부에서 여러 실행 흐름을 병행하는 구조이다. 프로세스 자원을 공유하므로 효율적인 데이터 공유가 가능하지만, 하나의 스레드에 문제가 생기면 전체 프로세스에 영향을 줄 수 있다.
* **여러 실행 파일의 멀티프로세스**: 각 프로그램이 독립적인 프로세스로 실행되는 구조이다. 자원 공유는 제한적이지만, 각 프로세스가 독립적이기 때문에 하나의 프로세스에 장애가 발생해도 다른 프로세스에 영향을 주지 않아 **안정성과 확장성** 측면에서 유리하다. 웹 서버나 데이터베이스와 같은 서버 애플리케이션에서 많이 사용된다. 이를 클러스터 외 연결되게 된다. 

클러스터 시스템은 이 멀티프로세스 개념을 더욱 확장한다. 물리적으로 떨어진 여러 대의 컴퓨터에 **실행 환경(컨테이너, Pod)** 자체를 분산시켜, 마치 하나의 거대한 시스템처럼 동작하게 만든다.

---

### 🌐 분산 처리 시스템: 쿠버네티스를 통한 확장

쿠버네티스는 단순한 컨테이너 오케스트레이션 도구를 넘어, 여러 대의 물리적/가상 머신(노드)과 그 위에 실행되는 컨테이너(Pod)들을 하나의 거대한 시스템으로 추상화하는 **분산 운영체제**와 같다.

* **노드(Node)**: 물리적 또는 가상 머신을 의미하며, 작업 실행의 물리적인 코어 또는 컴퓨팅 자원 집합으로 볼 수 있다.
* **팟(Pod)**: 쿠버네티스에서 배포되는 가장 작은 논리적인 실행 단위이다. 하나 이상의 컨테이너로 구성될 수 있으며, 전통적인 시스템의 **"프로세스" 또는 "작업의 단위"**에 해당한다.

#### 쿠버네티스는 거대한 '멀티프로세스 기반 분산 컨트롤러'

쿠버네티스를 전통적인 멀티스레드 시스템에 비유하자면, 아래와 같이 해석할 수 있다.

* **VM(Node)** = (물리적) 코어 또는 하나의 독립된 컴퓨팅 자원
* **Pod** = (논리적) 독립적인 실행 스레드 또는 프로세스 단위

즉, 전통적인 시스템에서 하나의 프로그램이 여러 스레드로 동작하듯, 쿠버네티스는 하나의 서비스를 여러 **Pod**로 나누어 각 **노드**에 분산 실행한다. 이는 멀티프로세스 방식을 분산 환경으로 확장한 것으로 이해할 수 있다.

이러한 쿠버네티스의 분산 아키텍처 덕분에 다음과 같은 이점을 얻을 수 있다.

* **수평 확장(Horizontal Scaling)**: 서비스 요청 증가 시, 새로운 Pod를 추가하여 여러 노드에 분산 배치함으로써 처리량을 늘릴 수 있다.
* **장애 복구(Self-healing)**: 특정 Pod나 노드에 문제가 발생하면, 쿠버네티스가 자동으로 문제가 있는 Pod를 재시작하거나 다른 노드에 새로운 Pod를 배포하여 서비스 연속성을 유지한다.
* **자동 확장(HPA, CA)**: Horizontal Pod Autoscaler(HPA)는 Pod의 부하에 따라 자동으로 Pod 개수를 조절하며, Cluster Autoscaler(CA)는 클러스터의 전체 부하에 따라 노드 개수를 자동으로 조절한다.
* **고가용성(High Availability, HA)**: 여러 노드에 Pod를 분산 배치하여, 단일 장애 지점(Single Point of Failure)을 제거하고 서비스의 연속성을 보장한다.

---

### 🛠️ 분산 시스템에서의 '모니터링'

분산 시스템에서는 수많은 구성 요소가 서로 상호작용하므로, 시스템의 상태를 효과적으로 모니터링하는 것이 매우 중요하다.

* **데스크톱 AOP(Aspect-Oriented Programming) 기반 모니터링**: 애플리케이션의 핵심 비즈니스 로직을 변경하지 않고, 메서드 실행 시간, 리소스 사용량 등지 않고, 메서드 실행 시간, 리소스 사용량 등을을 모니터링할 수 있는 기법이다. '비즈니스 로직 외부에 모니터링 로직을 주입'하여 동작한다.
* **쿠버네티스 DaemonSet**: 클러스터 내의 **모든 노드**에 특정 Pod(예: 메트릭 수집 에이전트, 로깅 에이전트)를 배포하여 실행하는 쿠버네티스 객체이다. 이를 통해 각 노드의 시스템 상태를 일관되고 비침투적인 방식으로 감시할 수 있다.

두 방식 모두 **비침투적 감시(Non-intrusive Monitoring)**라는 공통점을 가진다. 즉, 실제 서비스 로직을 변경하지 않고도 시스템의 성능과 상태를 효율적으로 모니터링하고 진단할 수 있게 한다.

---

### 🧾 결론: '나눔'과 '분배'의 원리

멀티코어, 멀티스레드, 멀티프로세스, 클러스터, 그리고 쿠버네티스에 이르기까지 이 모든 기술들은 결국 하나의 근본적인 질문으로 귀결된다.

> "누가(주체), 무엇을(작업), 어떻게(방식) 나누어서 처리할 것인가?"

작업을 가장 효율적이고 안정적으로 처리하기 위해 시스템의 물리적 한계(코어 수, 메모리)와 논리적 구조(스레드, 프로세스, 컨테이너)를 이해하고, 이를 바탕으로 작업 단위를 적절하게 나누어 적절한 주체에 분배하는 것이 중요하다. 이러한 '나눔'과 '분배'의 원리를 이해한다면, 어떤 복잡한 분산 처리 시스템이든 그 근본적인 설계 방향을 명확히 파악할 수 있다.
