
# 컨테이너, 분산 시스템, 분산 데이터 베이스

## 1. 컨테이너 환경에서의 파일 영속성 확보 전략

### 문제의 본질: 컨테이너의 휘발성 (Stateless 특성)

컨테이너는 이미지로부터 실행되는 임시적인 실행 환경이며, 일반적으로 상태(state)를 보존하지 않는다. 컨테이너가 중단되거나 삭제되면 컨테이너 내에서 생성된 모든 데이터는 사라진다. 이는 로그, 설정 파일, 데이터베이스와 같은 상태가 필요한(Stateful) 서비스를 구현할 때 심각한 문제가 될 수 있다.

이 문제를 해결하기 위해 컨테이너 외부에 데이터를 저장할 구조가 필수적으로 필요하다.

### Docker 환경의 해결책: Volume 기반의 영속성 관리

* **호스트 볼륨 마운트**
  호스트 머신의 디렉터리를 컨테이너 내부로 마운트한다. 컨테이너 재시작에도 데이터가 유지되지만, 호스트 환경에 종속적이기 때문에 이식성과 유연성이 떨어지는 단점이 있다.

* **도커 관리 볼륨 (Docker Managed Volume)**
  Docker가 관리하는 전용 스토리지 영역으로, `docker volume create`를 통해 생성된다. 호스트 파일 시스템과 분리되어 있어 관리가 간편하며, 스냅샷, 백업 등에 유리하다.

### Kubernetes 환경의 진화된 구조: PV, PVC, StorageClass

Kubernetes에서는 Pod가 어떤 노드에서 실행될지 예측할 수 없으므로, 로컬 디스크를 마운트하는 방식은 사용할 수 없다. Kubernetes는 스토리지 추상화를 위해 다음과 같은 구조를 제공한다.

* **PersistentVolume (PV)**
  클러스터 수준에서 관리되는 실제 스토리지 자원으로, AWS EBS, NFS, GCE Persistent Disk, Ceph 등의 다양한 형태가 있다. Pod의 라이프사이클과는 독립적으로 존재한다.

* **PersistentVolumeClaim (PVC)**
  사용자가 필요한 스토리지 사양(용량, 접근 모드 등)을 정의한 요청서이다. Kubernetes는 PVC와 조건이 일치하는 PV를 찾아 자동으로 바인딩한다.

* **StorageClass**
  PV를 동적으로 생성하기 위한 템플릿이다. 예를 들어, AWS에서는 스토리지 클래스에 따라 프로비저닝되는 EBS 볼륨의 속성(SSD, HDD 등)이 달라질 수 있다.

이러한 구조를 통해 개발자는 클러스터의 스토리지 백엔드에 대한 복잡한 지식 없이도 안정적인 영속적 저장소를 활용할 수 있다.

---

## 2. 분산 파일 시스템의 원리와 실제

### 분산 파일 시스템이 필요한 이유

단일 서버는 용량, 성능, 장애 허용성 측면에서 한계가 있다. 분산 파일 시스템(Distributed File System, DFS)은 여러 대의 서버를 묶어 하나의 논리적 파일 시스템처럼 동작하도록 구성하여 확장성, 고가용성, 내결함성을 확보하는 핵심 기술이다.

### 핵심 설계 원리

1. **Sharding / Chunking**
   대용량 파일을 일정 크기의 블록 또는 청크로 나눈다.

2. **Distribution**
   청크들을 여러 노드에 분산 저장하여 입출력 부하를 분산하고 저장 용량을 수평적으로 확장할 수 있다.

3. **Replication**
   동일한 청크를 여러 노드에 복제하여 장애 발생 시에도 데이터를 복구할 수 있다.

4. **Metadata Management**
   파일의 구성 블록이 어느 노드에 있는지를 관리하는 메타데이터가 필요하다.

### 대표적인 분산 파일 시스템

#### Hadoop HDFS

* **구조**: NameNode(메타데이터 관리) + DataNode(실제 데이터 저장)
* **특징**: 대용량 파일의 순차적 읽기에 최적화되어 있으며, Write-Once, Read-Many 방식의 데이터 처리에 유리하다. 단, 임의 접근이나 실시간 처리에는 부적합하다.

#### GlusterFS

* **구조**: 중앙 메타데이터 서버 없이, 모든 노드가 동등한 지위를 갖는다.
* **특징**: 해시 기반 탐색 알고리즘으로 단일 장애 지점(SPOF)을 제거하며, 다양한 워크로드에 적용할 수 있다.

#### CephFS

* **구조**: RADOS 기반의 오브젝트 스토리지 계층 위에 구축되며, 메타데이터 서버(MDS)와 OSD(Object Storage Daemon)로 구성된다.
* **특징**: 오브젝트, 블록, 파일 스토리지를 모두 제공하는 통합 플랫폼이며, CRUSH 알고리즘을 통해 데이터 분산과 복제를 자동화한다. 매우 높은 확장성과 데이터 일관성을 제공한다.

---
## PostgreSQL의 Active-Active 구성 

### 1. 전통적인 Master-Slave 구조란?

* **마스터(Master)**:
  모든 \*\*쓰기 작업(INSERT, UPDATE, DELETE)\*\*은 이 서버에서만 처리된다. 데이터를 직접 수정할 수 있는 유일한 서버다.

* **슬레이브(Slave)**:
  마스터의 데이터를 **복사해서 읽기 전용**으로 사용한다. 주로 조회(SELECT) 전용이다. 마스터가 변경한 내용을 복제받아 동기화된다.

* 예시:
  쇼핑몰 서버에서 주문 내역은 마스터에서 저장하고, 고객이 자신의 주문 내역을 조회하는 건 슬레이브에서 처리함.

* **장점**: 쓰기와 읽기를 분리해서 성능 분산

* **단점**: 마스터가 죽으면 쓰기를 할 수 없어 서비스 중단

### 2. Active-Active 구조란?

* 여러 개의 서버가 **동시에 읽기와 쓰기**를 할 수 있는 구조다.

* 즉, **모든 서버가 마스터 역할**을 수행한다. 서로 데이터를 주고받으며 동기화한다.

* 예시:
  한국에 있는 사용자 요청은 한국 서버가, 미국 사용자는 미국 서버가 바로 처리한다.
  둘 다 주문을 저장할 수 있고, 그 정보는 서로에게 전달되어 동기화된다.

* **장점**:

    * 지역마다 가까운 서버에서 빠르게 요청 처리 가능
    * 하나의 서버가 죽어도 다른 서버에서 계속 처리 가능
    * 진정한 고가용성과 무중단 서비스를 실현할 수 있음

* **단점**:

    * 동시에 같은 데이터를 수정하면 **충돌(conflict)** 발생 가능
    * 이를 해결하기 위해 복잡한 충돌 처리 전략이 필요함 (예: 마지막에 저장된 쪽을 살리기 등)

---

### 3. PostgreSQL에서 Active-Active는 어떻게 구현할까?

PostgreSQL은 기본적으로 Master-Slave 구조를 중심으로 만들어졌지만, **추가 도구**를 사용해서 Active-Active 환경을 구현할 수 있다.

#### 대표적인 방법

* **BDR (Bi-Directional Replication)**
  PostgreSQL 서버끼리 **양방향으로 데이터를 주고받는 구조**를 지원하는 확장 기능이다.

* **pglogical**
  PostgreSQL의 **논리적 복제(logical replication)** 기능을 활용해 여러 서버 간 데이터를 주고받게 해준다.

이러한 도구들을 사용하면 **두 개 이상의 PostgreSQL 서버가 서로에게 데이터를 복제하면서, 모두 쓰기 가능한 상태**를 만들 수 있다.

---

### 4. 정리: Master-Slave vs Active-Active

| 항목         | Master-Slave   | Active-Active             |
| ---------- | -------------- | ------------------------- |
| 쓰기 가능한 서버  | 마스터 1대         | 모든 서버                     |
| 읽기 가능한 서버  | 모든 서버          | 모든 서버                     |
| 서버 간 복제 방향 | 마스터 → 슬레이브     | 양방향 (서로 주고받음)             |
| 장애 발생 시 영향 | 마스터가 죽으면 쓰기 불가 | 한 서버가 죽어도 다른 서버로 계속 처리 가능 |
| 충돌 가능성     | 없음             | 있음 (동시 수정 시 충돌 처리 필요)     |
| 복잡성        | 낮음             | 높음 (복제와 충돌 처리 고려해야 함)     |

---

### 5. 컨테이너 환경과 Active-Active

   - 컨테이너 환경에서는 애플리케이션 인스턴스가 언제든지 생성되고 삭제될 수 있으므로, 데이터베이스도 이를 뒷받침할 수 있는 탄력적이고 중단 없는 구조가 필요하다.

   - PostgreSQL을 단일 마스터에 의존하면, 컨테이너 기반 분산 환경에서 **단일 장애 지점(SPOF)**이 발생할 수 있다.

   - Active-Active 구조는 컨테이너 기반 마이크로서비스 환경에서 무중단 배포, 자동 확장, 다중 인스턴스 간 부하 분산 등을 가능하게 한다.

 결론: 컨테이너 기반 마이크로서비스와 Active-Active 구조는 상호보완적이다. Stateless 앱과 Stateful DB 간의 연결을 안전하게 만들려면 PostgreSQL도 무중단 구조를 갖춰야 한다.

---

### 6. 분산 시스템 관점에서의 Active-Active

   - Active-Active PostgreSQL 구성은 복수 노드 간의 동시 쓰기와 동기화라는 분산 시스템의 핵심 문제에 정면으로 대응한다.

   - 이는 **데이터 일관성(C)**과 가용성(A) 사이의 균형(CAP 이론)에서 높은 가용성을 우선시하며, 네트워크 파티션 시 충돌 처리 등 분산 트랜잭션 처리가 중요한 이슈로 떠오른다.

   - 분산 시스템에서는 네트워크 지연, 분할(brain split), 장애 상황 등 다양한 시나리오를 고려해 **복제 및 충돌 해결 전략(LWW, CRDT 등)**이 필요하다.

   결론: PostgreSQL의 Active-Active 구조는 고가용 분산 시스템의 핵심 요구사항인 장애 복구, 지역 분산 처리, 무중단 서비스 구현에 직결된다.

---

### 7. 분산 파일 시스템과 Active-Active의 공통 맥락

   - CephFS, GlusterFS 같은 분산 파일 시스템은 데이터의 복제, 일관성 보장, 무중단 접근을 위해 내부적으로 Active-Active 구조 또는 유사 구조를 사용한다.

   - PostgreSQL Active-Active도 유사하게, 데이터의 복제와 일관성 문제를 다루며, 사용자 관점에서는 하나의 논리적 데이터베이스로 작동한다.

   - 또한, **데이터 볼륨 관리(PV, PVC)**와 연계하여 PostgreSQL의 데이터를 분산 파일 시스템 위에 저장하면, Active-Active의 물리적 스토리지 확장성과 안정성도 높일 수 있다.

   결론: PostgreSQL Active-Active는 단순히 데이터베이스 복제를 넘어서, 스토리지와 시스템 전반에 걸친 고가용성 아키텍처와 직결된다.